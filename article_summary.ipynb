{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Task 1\n",
    "Write a Python script that loads an article from the internet and generates a summary and title\n",
    "using a large language model (LLM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries that I will be using in the project\n",
    "\n",
    "import requests                          #GET Request from the server is needed to get HTML Document.\n",
    "from bs4 import BeautifulSoup            #For Parsing HMTL.\n",
    "import re                                #Manipulating text (e.g. removing words, such as in my case).\n",
    "from typing import List                  #Not necessary at all, I just saw it from a book and I though it would be good practice and also look good.\n",
    "from dotenv import load_dotenv           #Loading .env with API keys.\n",
    "import os\n",
    "\n",
    "from langchain_openai import ChatOpenAI  #OpenAI Model\n",
    "from langchain.prompts import PromptTemplate #Prompt Template element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a method for loading the '.env' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure():\n",
    "    load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "configure()                                    #Load .env\n",
    "openai_api_key = os.getenv('api_key')          #Fetch from file\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key  #Set Enviroment API Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Scraping an article for raw, readable and clean imput text\n",
    "Methods \"fetch_parse\" and \"clean_text\" for fetching the text from the web and transforming it into a nice and readable block of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 - fetch_parse\n",
    "Fetches all information in 'p' HTML tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_parse(url: str, headers: dict) -> List[str]:                 #I saw this approach for defining methods in a book and decided to stick with it.\n",
    "    \n",
    "    page_to_be_scraped = requests.get(url, headers=headers)            #Submit a GET request to the server.\n",
    "    soup = BeautifulSoup(page_to_be_scraped.text, \"html.parser\")       #Parse the HTML file.\n",
    "    p_paragraphs = soup.find_all(\"p\")                                  #<---Finds paragraph(<p>) tags in the HTML file.\n",
    "    pure_paragraphs = [p.get_text(strip=True) for p in p_paragraphs]   #Extracts the text from the <p> paragraphs.\n",
    "\n",
    "    return pure_paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 - clean_text\n",
    "Cleans the input in order to ouput clean raw text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text_list: list) -> List:     #Again, here I am using the same approach because I tihnk it makes it better readable.\n",
    "    text = \"\\n\".join(text_list)              # Convert list to a single string\n",
    "\n",
    "    # Removing common words that are used in web articles se we can clean the text as much as possible.\n",
    "    text = re.sub(r\"(?i)\\b(Share this story:|Tags:|Categories:|Subscribe now|See also:|Want to learn more about .*?)\\b.*\", \"\", text) \n",
    "\n",
    "    # Detect and remove block of short lines at the start (tags)\n",
    "    lines = text.split(\"\\n\")\n",
    "    filtered_lines = []\n",
    "    for line in lines:\n",
    "        if len(line.split()) > 5:            # Keep only the lines that have more than 5 words\n",
    "            filtered_lines.append(line)\n",
    "        elif filtered_lines:                 # Once we hit real content -> stop filtering\n",
    "            filtered_lines.append(line)\n",
    "\n",
    "    text = \"\\n\".join(filtered_lines)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 - Clean Text Result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://news.bg/int-politics/tramp-razgovaryal-s-putin-za-kraya-na-voynata-v-ukrayna.html\" #URL to be scraped\n",
    "headers = {'User-Agent': 'Mozilla/5.0'} #Here we are using an User-Agent because many websites have protection against bots that are doing the same thing we are\n",
    "\n",
    "\n",
    "cleaned_text = clean_text(fetch_parse(url, headers)) #Using both methods I created to clean the get and clean the text from the article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Chosing Model and Creating a Prompt Template\n",
    "Selecting Model and Configuring Context. \n",
    "\n",
    "For this specific task I decided to go with a simpler approach, because the model will be used for summarizing articles on the web and not books, ect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI(model_name='gpt-4o-mini') #LLM Model Selection\n",
    "\n",
    "#Template\n",
    "template = \"\"\"                           \n",
    "Please provide a short and simple summary of a couple of sentences of the following text:\\n TEXT: {cleaned_text}\\n in the format:\n",
    "\n",
    "Title:\n",
    "    [Insert Title Here]\n",
    "\n",
    "    Summary:\n",
    "    [Insert Summary Here]\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"cleaned_text\"],   #I am using 1 variable that will be injected into the prompt template - \"cleaned_text\".\n",
    "    template=template                   #Argument for a template takes 'template' variable that I created a few rows above.\n",
    ")\n",
    "\n",
    "formatted_prompt = prompt.format(cleaned_text=cleaned_text) #Prompt formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2.1 - Number of Tokens\n",
    "It is good practice to know how many tokens the article contains and how many tokens can the model handle, for example the model I chose to work with (GPT-4o-mini) which can handle 128,000-token context window and 16,384 output tokens per request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1641"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2.2 - Summarized Result\n",
    "Below is the summarized text from the article provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:  \n",
      "Trump Discusses Ukraine War with Putin\n",
      "\n",
      "Summary:  \n",
      "U.S. President Donald Trump revealed he has spoken with Russian President Vladimir Putin about ending the war in Ukraine, stating, \"Putin wants people to stop dying.\" Trump indicated he has a specific plan to resolve the conflict and expressed hope for a quick resolution, while also mentioning a possible upcoming meeting with Ukrainian President Volodymyr Zelensky to discuss the war's end.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(formatted_prompt).content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
