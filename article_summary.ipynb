{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "Write a Python script that loads an article from the internet and generates a summary and title\n",
    "using a large language model (LLM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries that I will be using in the project\n",
    "import requests\n",
    "from bs4 import BeautifulSoup #For Parsing HMTL\n",
    "import re #Manipulating text (e.g. removing words, such as in my case)\n",
    "from typing import List #Not necessary at all, I just saw it from a book and I though it would be good practice and also look good.\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import(\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure():\n",
    "    load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "configure()\n",
    "openai_api_key = os.getenv('api_key')\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Scraping an article for raw, readable and clean imput text\n",
    "Methods \"fetch_parse\" and \"clean_text\" for fetching the text from the web and transforming it into a nice and readable block of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 - fetch_parse\n",
    "Fetches all information in 'p' HTML tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_parse(url: str, headers: dict) -> List[str]:\n",
    "    page_to_be_scraped = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(page_to_be_scraped.text, \"html.parser\")\n",
    "    p_paragraphs = soup.find_all(\"p\") #Finds paragraph(<p>) tags in the HTML file\n",
    "    pure_paragraphs = [p.get_text(strip=True) for p in p_paragraphs]\n",
    "\n",
    "    return pure_paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 - clean_text\n",
    "Cleans the input in order to ouput clean raw text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text_list: list) -> List:\n",
    "    # Convert list to a single string\n",
    "    text = \"\\n\".join(text_list)\n",
    "\n",
    "    # Removing common metadata\n",
    "    text = re.sub(r\"(?i)\\b(Share this story:|Tags:|Categories:|Subscribe now|See also:|Want to learn more about .*?)\\b.*\", \"\", text)\n",
    "\n",
    "    # Detect and remove block of short lines at the start (tags)\n",
    "    lines = text.split(\"\\n\")\n",
    "    filtered_lines = []\n",
    "    for line in lines:\n",
    "        if len(line.split()) > 5:  # Keep only the lines that have more than 5 words\n",
    "            filtered_lines.append(line)\n",
    "        elif filtered_lines:  # Once we hit real content -> stop filtering\n",
    "            filtered_lines.append(line)\n",
    "\n",
    "    text = \"\\n\".join(filtered_lines)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 - Clean Text Result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://news.bg/politics/peevski-obeshtava-da-ne-e-pateritsa-za-regulatorite.html\" #URL to be scraped\n",
    "headers = {'User-Agent': 'Mozilla/5.0'} #Here we are using an User-Agent because many websites have protection against bots that are doing the same thing we are\n",
    "\n",
    "\n",
    "cleaned_text = clean_text(fetch_parse(url, headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Setting up LLM and APIs'\n",
    "Selecting Model and Configuring Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_messages=[\n",
    "    SystemMessage(content='You are a text summarization tool. You will be tasked to summarize input text'),\n",
    "    HumanMessage(content=f'Please provide a short and concise summary of the following speech:\\n TEXT: {cleaned_text}')\n",
    "]\n",
    "llm=ChatOpenAI(model_name='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2.1 - Number of Tokens\n",
    "It is good practice to know how many tokens the article contains and how many tokens can the model handle, for example the model I chose to work with (GPT-4o-mini) which can handle 128,000-token context window and 16,384 output tokens per request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "971"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2.2 - Summarized Result\n",
    "Below is the summarized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Делян Пеевски, лидер на ДПС-Ново начало, заяви, че неговата парламентарна група няма да подкрепи разпределението на регулатори от изтекъл мандат и изключва участие с кандидати. Той остави отворена възможността да сменят регулаторите след предсрочни парламентарни избори, ако ДПС-Ново начало стане първа политическа сила. Пеевски акцентира на необходимостта от контрол над цените на хранителните стоки и призова за обединение на политическите лидери срещу влиянието на Джордж Сорос в България. Той отправи призив към Бойко Борисов да стане национален лидер в усилията за освобождаване на страната от това влияние.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(chat_messages).content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
