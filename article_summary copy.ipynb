{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "Write a Python script that loads an article from the internet and generates a summary and title\n",
    "using a large language model (LLM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries that I will be using in the project\n",
    "import requests\n",
    "from bs4 import BeautifulSoup #For Parsing HMTL\n",
    "import re #Manipulating text (e.g. removing words, such as in my case)\n",
    "from typing import List #Not necessary at all, I just saw it from a book and I though it would be good practice and also look good.\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain import PromptTemplate\n",
    "from langchain.schema import(\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure():\n",
    "    load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "configure()\n",
    "openai_api_key = os.getenv('api_key')\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Scraping an article for raw, readable and clean imput text\n",
    "Methods \"fetch_parse\" and \"clean_text\" for fetching the text from the web and transforming it into a nice and readable block of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 - fetch_parse\n",
    "Fetches all information in 'p' HTML tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_parse(url: str, headers: dict) -> List[str]:\n",
    "    page_to_be_scraped = requests.get(url, headers=headers)\n",
    "    page_to_be_scraped.raise_for_status() #Ensuring fetching was successful\n",
    "    soup = BeautifulSoup(page_to_be_scraped.text, \"html.parser\")\n",
    "    \n",
    "    p_paragraphs = soup.find_all(\"p\") #Finds paragraph(<p>) tags in the HTML file\n",
    "    pure_paragraphs = [p.get_text(strip=True) for p in p_paragraphs]\n",
    "\n",
    "    return pure_paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 - clean_text\n",
    "Cleans the input in order to ouput clean raw text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text_list: list) -> List:\n",
    "    # Convert list to a single string\n",
    "    text = \"\\n\".join(text_list)\n",
    "\n",
    "    # Removing common metadata\n",
    "    text = re.sub(r\"(?i)\\b(Share this story:|Tags:|Categories:|Subscribe now|See also:|Want to learn more about .*?)\\b.*\", \"\", text)\n",
    "\n",
    "    # Detect and remove block of short lines at the start (tags)\n",
    "    lines = text.split(\"\\n\")\n",
    "    filtered_lines = []\n",
    "    actual_content = False\n",
    "    \n",
    "    for line in lines:\n",
    "        if len(line.split()) > 5:  # Keep only the lines that have more than 5 words\n",
    "            actual_content = True\n",
    "            filtered_lines.append(line)\n",
    "        elif filtered_lines:  # Once we hit real content -> stop filtering\n",
    "            filtered_lines.append(line)\n",
    "\n",
    "    text = \"\\n\".join(filtered_lines)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 - Clean Text Result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11 225 парфюма задържаха митнически служители от ТД Митница София и ТД Митница Русе в рамките на ден при две отделни проверки – една на Митнически пункт Калотина и една в района на Дунав мост – Видин. Една част от задържаните парфюми са контрабандни, а други са иззети по подозрение, че са фалшиви. И двете проверки са извършени на 02.02.2025 г., парфюмите са превозвани с други стоки, тръгнали от България, и били опаковани в необозначени кашони.\\n2874 контрабандни парфюма са задържани при проверка на български товарен автомобил, излизащ от страната през Митнически пункт Калотина. Митническите служители от ТД Митница София селектират за проверка излизащ от страната през ГКПП Калотина товарен автомобил, пътуващ със стока към Франция. След като водачът не декларирал друго освен описаната в придружаващите документи стока, товарът е отклонен за щателна митническа проверка и сканиране с рентгенова апаратура. Набелязани са зони с подозрителна плътност, за които при последващата физическа проверка митническите служители от МП Калотина установяват, че представляват три палета с парфюми и тоалетни води на различни марки, с общо количество 2874 броя. Сред ароматите от 44 разновидности преобладават разфасовки от 30, 75 или 100 мл., като повечето са парфюми от известни модни марки. Стоките са задържани, а на водача е съставен акт по Закона за митниците.\\nНа същата дата – 02.02.2025 г., на подстъпа към Дунав мост - Видин митнически служители от ТД Митница Русе извършват проверка на български товарен автомобил, превозващ групажна стока от България към Италия. Селектирани са две от пратките в групажа, описани в товарителницата като „козметика“. След като на място отварят част от кашоните, митническите инспектори установяват, че в тях се съдържат парфюмерийни изделия от известни марки. Водачът и товарният автомобил са съпроводени до Митническо бюро Видин, където в халето са разтоварени общо пет палета с кашони без надписи и маркировка. При извършената щателна митническа проверка е установено, че те съдържат общо 8351 парфюми и тоалетни води от 31 известни търговски марки. Стоките са задържани поради възникнали съмнения, че нарушават права на търговски марки.\\n\\nОбщото количество на задържаните от служителите на ТД Митница София и ТД Митница Русе контрабандни и фалшиви парфюми е 11 225 броя.\\nПри друг случай, отново в неделя, 02.02.2025г., митнически служители от ТД Митница Русе, отклоняват автобус, пътуващ от Турция към Румъния през Дунав мост – Русе. При проверка на багажа на един от пътниците са открити 1005 блузи с къс ръкав, носещи надписи и изображения на девет известни марки. Установено е, че стоките идват от Турция, поради което на преносителя им – турски гражданин, е съставен акт за контрабанда по Закона за митниците.\\nИзвършените проверки от ТД Митница Русе са част от компенсиращите мерки на Агенция „Митници“ във връзка с отпадането\\n\\nСвързани новини\\n\\n1Слави\\n15:2606.02.2025\\n2в парфюма\\n15:3806.02.2025\\n3Колко да е фалшив?\\n15:4106.02.2025\\n4на Изток от Виена\\nКоментиран от#8\\n15:5806.02.2025\\n\\n5Професор Вучков\\nКоментиран от#7,#12\\n16:0006.02.2025\\n6То нещо истинско\\n16:0806.02.2025\\n7Оригинален на Армуни\\nДо коментар#5от \"Професор Вучков\":\\n16:0906.02.2025\\n8Аромата им е еднаква смрад\\nДо коментар#4от \"на Изток от Виена\":\\n16:1106.02.2025\\n9АГЕНТ 007\\n16:1206.02.2025\\n10Този коментар е премахнат от модератор.\\n11Много корумпирани ченгета има\\n16:1606.02.2025\\n12КОСТОФ\\nДо коментар#5от \"Професор Вучков\":\\n16:1806.02.2025\\nОщеновини от\\xa0Крими\\nЛовци на бисери\\n“Самият факт да откраднеш милион и половина и да се предадеш е гаранция за невменяемост.„\\nТоп 5четени|коментирани|нови\\nЧетете ни в Google News'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://fakti.bg/krimi/947637-nad-11-000-kontrabandni-i-falshivi-parfuma-za-den\" #URL to be scraped\n",
    "headers = {'User-Agent': 'Mozilla/5.0'} #Here we are using an User-Agent because many websites have protection against bots that are doing the same thing we are\n",
    "\n",
    "\n",
    "cleaned_text = clean_text(fetch_parse(url, headers))\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Setting up LLM and APIs'\n",
    "Selecting Model and Configuring Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_template=f'''\n",
    "Write a summary of the following article and give it a title:\n",
    "Article: '{cleaned_text}'''\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    input_variables=['text'],\n",
    "    template=generic_template\n",
    ")\n",
    "complete_prompt = prompt.format(text=cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI(model_name='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2.1 - Number of Tokens\n",
    "It is good practice to know how many tokens the article contains and how many tokens can the model handle, for example the model I chose to work with (GPT-4o-mini) which can handle 128,000-token context window and 16,384 output tokens per request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1329\n",
      "1346\n"
     ]
    }
   ],
   "source": [
    "print(llm.get_num_tokens(cleaned_text))\n",
    "print(llm.get_num_tokens(complete_prompt)) #We can check if the added characters from the prompt do not exceed limits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2.2 - Summarized Result\n",
    "Below is the summarized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ivan\\AppData\\Local\\Temp\\ipykernel_22268\\3743950683.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain=LLMChain(llm=llm,prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "llm_chain=LLMChain(llm=llm,prompt=prompt)\n",
    "summary=llm_chain.invoke({'text':cleaned_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '**Title: Massive Seizure of Perfumes at Bulgarian Borders: Over 11,000 Confiscated**\\n\\nSummary: On February 2, 2025, customs officials from the Sofia and Ruse Customs Directorates seized a total of 11,225 perfumes during two separate inspections at the Kalotina and Danube Bridge - Vidin checkpoints. The inspections discovered a mix of contraband and counterfeit perfumes hidden among other goods in unmarked boxes. At Kalotina, authorities confiscated 2,874 counterfeit perfumes destined for France from a Bulgarian truck. Meanwhile, at the Danube Bridge, 8,351 perfumes of well-known brands were found in a shipment mistakenly labeled as \"cosmetics\" en route to Italy. Additionally, customs officials intercepted a bus carrying over 1,000 counterfeit clothes from Turkey. The inspections are part of measures by the Customs Agency in response to the removal of certain restrictions.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
